{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084645d8",
   "metadata": {},
   "source": [
    "# ATLAS: Publication-Quality Experiments for IEEE\n",
    "\n",
    "**Multi-Task Federated Learning with Heterogeneous Devices**  \n",
    "**Session-Based Training for Long Runs (30+ Rounds)**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Experimental Configuration\n",
    "\n",
    "### Publication Parameters\n",
    "- **Rounds**: 30 (split into 15+15 sessions if needed)\n",
    "- **Samples per client**: 3000-5000 (publication quality)\n",
    "- **Local epochs**: 3\n",
    "- **Checkpointing**: Every 5 rounds (automatic resuming)\n",
    "\n",
    "### Multi-Domain Tasks\n",
    "- **NLP**: SST-2 (sentiment), MRPC (paraphrase), CoLA (grammar), QNLI (QA)\n",
    "- **Vision** (optional): CIFAR-10, MNIST variants\n",
    "- **Speech** (optional): Speech commands\n",
    "\n",
    "### Models Supported\n",
    "- DistilBERT (default)\n",
    "- BERT-base\n",
    "- RoBERTa\n",
    "- GPT-2\n",
    "- (Easily extensible)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Features\n",
    "\n",
    "1. **Session-based training**: Split 30 rounds into multiple Colab sessions\n",
    "2. **Automatic checkpoint resume**: Continue from last saved checkpoint\n",
    "3. **Model-agnostic**: Test different architectures\n",
    "4. **Multi-domain**: True heterogeneous multi-task FL\n",
    "5. **IEEE-quality results**: Rigorous parameters for publication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04797a64",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac36c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch transformers datasets peft scikit-learn scipy numpy pandas matplotlib\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"‚úì GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or update repository\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if Path('ATLAS').exists():\n",
    "    %cd ATLAS\n",
    "    !git pull origin main\n",
    "    print(\"‚úì Repository updated\")\n",
    "else:\n",
    "    !git clone https://github.com/mahmoudmayaleh/ATLAS.git\n",
    "    %cd ATLAS\n",
    "    print(\"‚úì Repository cloned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67cfd9f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Experiment 1: ATLAS Full Pipeline (30 Rounds)\n",
    "\n",
    "**Session-Based Training**:\n",
    "- Session 1: Rounds 1-15 (~2-3 hours)\n",
    "- Session 2: Rounds 16-30 (~2-3 hours)\n",
    "\n",
    "Checkpoints saved every 5 rounds automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c1de6f",
   "metadata": {},
   "source": [
    "### Session 1: Rounds 1-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session 1: Train rounds 1-15\n",
    "# This will save checkpoints at rounds 5, 10, 15\n",
    "\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --max-rounds 15 \\\n",
    "    --ablation atlas \\\n",
    "    --model distilbert-base-uncased \\\n",
    "    --tasks sst2 mrpc cola \\\n",
    "    --clients-per-task 3 \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3\n",
    "\n",
    "print(\"\\n‚úì Session 1 complete (Rounds 1-15)\")\n",
    "print(\"‚úì Checkpoint saved: checkpoints/atlas_round_15.pkl\")\n",
    "print(\"\\n‚è∏Ô∏è  You can now disconnect and resume in a new session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999e4e2",
   "metadata": {},
   "source": [
    "### Session 2: Rounds 16-30 (Resume from checkpoint)\n",
    "\n",
    "**Run this in a NEW Colab session** (or continue in same session):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session 2: Resume from round 15, continue to round 30\n",
    "# Will automatically load checkpoint and continue training\n",
    "\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --resume checkpoints/atlas_round_15.pkl \\\n",
    "    --ablation atlas \\\n",
    "    --model distilbert-base-uncased \\\n",
    "    --tasks sst2 mrpc cola \\\n",
    "    --clients-per-task 3 \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3\n",
    "\n",
    "print(\"\\n‚úì Session 2 complete (Rounds 16-30)\")\n",
    "print(\"‚úì Final results saved: results/atlas_integrated_full_atlas.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc6d86",
   "metadata": {},
   "source": [
    "### Alternative: Single Session (if you have 4+ hours)\n",
    "\n",
    "If your Colab session lasts long enough, run all 30 rounds at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffe25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full 30 rounds in one go (3-4 hours)\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --ablation atlas \\\n",
    "    --model distilbert-base-uncased \\\n",
    "    --tasks sst2 mrpc cola \\\n",
    "    --clients-per-task 3 \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856df655",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Experiment 2: Ablation Studies\n",
    "\n",
    "**Compare**:\n",
    "1. ATLAS Full (all 4 phases)\n",
    "2. FedAvg per Cluster (no Laplacian)\n",
    "3. Local Only (no aggregation)\n",
    "\n",
    "Each runs 30 rounds for rigorous comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08230b2b",
   "metadata": {},
   "source": [
    "### 2.1: FedAvg per Cluster (Ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5188085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation: FedAvg within clusters (Phase 1-3 only)\n",
    "# Session 1: Rounds 1-15\n",
    "\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --max-rounds 15 \\\n",
    "    --ablation fedavg_cluster \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3\n",
    "\n",
    "# Save checkpoint location\n",
    "fedavg_checkpoint = \"checkpoints/atlas_round_15.pkl\"\n",
    "print(f\"\\n‚úì FedAvg ablation - Session 1 complete\")\n",
    "print(f\"‚úì Resume with: --resume {fedavg_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session 2: Continue rounds 16-30\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --resume checkpoints/atlas_round_15.pkl \\\n",
    "    --ablation fedavg_cluster \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157b792",
   "metadata": {},
   "source": [
    "### 2.2: Local Only Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04947da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Local training only (no aggregation)\n",
    "# Faster since no communication, but worse accuracy\n",
    "\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --ablation local_only \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff3f04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¨ Experiment 3: Lambda (Œ∑) Sweep\n",
    "\n",
    "Test different Laplacian regularization strengths: {0.0, 0.01, 0.1, 0.5, 1.0}\n",
    "\n",
    "This helps find optimal personalization vs convergence tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c96a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda sweep across 5 values\n",
    "# Note: This runs 5 experiments √ó 30 rounds each\n",
    "# Recommended: Run in multiple sessions or reduce rounds\n",
    "\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --lambda-sweep \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3\n",
    "\n",
    "print(\"\\n‚úì Lambda sweep complete\")\n",
    "print(\"‚úì Results saved: results/lambda_sweep_full_atlas.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71ead5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé® Experiment 4: Different Models\n",
    "\n",
    "Test ATLAS with different backbone models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89b248",
   "metadata": {},
   "source": [
    "### 4.1: BERT-base (110M params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT-base (more parameters than DistilBERT)\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --max-rounds 15 \\\n",
    "    --ablation atlas \\\n",
    "    --model bert-base-uncased \\\n",
    "    --tasks sst2 mrpc cola \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3\n",
    "\n",
    "print(\"\\n‚úì BERT-base Session 1 complete\")\n",
    "print(\"‚úì Continue with: --resume checkpoints/atlas_round_15.pkl --model bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89487858",
   "metadata": {},
   "source": [
    "### 4.2: RoBERTa-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoBERTa-base (better performance on many tasks)\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --max-rounds 15 \\\n",
    "    --ablation atlas \\\n",
    "    --model roberta-base \\\n",
    "    --tasks sst2 mrpc cola \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38c79c",
   "metadata": {},
   "source": [
    "### 4.3: GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8774d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 (decoder-only, good for generation tasks)\n",
    "!python experiments/atlas_integrated.py \\\n",
    "    --mode full \\\n",
    "    --rounds 30 \\\n",
    "    --max-rounds 15 \\\n",
    "    --ablation atlas \\\n",
    "    --model gpt2 \\\n",
    "    --tasks sst2 mrpc cola \\\n",
    "    --samples 5000 \\\n",
    "    --local-epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0e431",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Results Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad600be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load all experiment results\n",
    "results_dir = Path('results')\n",
    "experiments = {}\n",
    "\n",
    "# Define experiment files\n",
    "result_files = {\n",
    "    'ATLAS (DistilBERT)': 'atlas_integrated_full_atlas.json',\n",
    "    'FedAvg Cluster': 'atlas_integrated_full_fedavg_cluster.json',\n",
    "    'Local Only': 'atlas_integrated_full_local_only.json',\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä LOADING EXPERIMENTAL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, filename in result_files.items():\n",
    "    filepath = results_dir / filename\n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'r') as f:\n",
    "            experiments[name] = json.load(f)\n",
    "        print(f\"‚úì Loaded: {name}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Missing: {name} ({filename})\")\n",
    "\n",
    "if not experiments:\n",
    "    print(\"\\n‚ùå No results found! Run experiments first.\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Loaded {len(experiments)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f55519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for exp_name, results in experiments.items():\n",
    "    final_accs = results.get('final_accuracies', {})\n",
    "    round_metrics = results.get('round_metrics', [])\n",
    "    \n",
    "    if not final_accs or not round_metrics:\n",
    "        continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    client_accs = list(final_accs.values())\n",
    "    avg_acc = np.mean(client_accs)\n",
    "    std_acc = np.std(client_accs)\n",
    "    min_acc = min(client_accs)\n",
    "    max_acc = max(client_accs)\n",
    "    \n",
    "    # Communication cost\n",
    "    total_comm = 0\n",
    "    for rm in round_metrics:\n",
    "        up = rm.get('comm_upload_bytes', {})\n",
    "        down = rm.get('comm_download_bytes', {})\n",
    "        if isinstance(up, dict):\n",
    "            total_comm += sum(up.values()) + sum(down.values())\n",
    "        else:\n",
    "            total_comm += up + down\n",
    "    total_comm_mb = total_comm / (1024**2)\n",
    "    \n",
    "    # Time\n",
    "    total_time_min = sum(rm.get('time_seconds', 0) for rm in round_metrics) / 60\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Experiment': exp_name,\n",
    "        'Rounds': len(round_metrics),\n",
    "        'Avg Accuracy': f'{avg_acc:.4f}',\n",
    "        'Std Dev': f'{std_acc:.4f}',\n",
    "        'Min Acc': f'{min_acc:.4f}',\n",
    "        'Max Acc': f'{max_acc:.4f}',\n",
    "        'Comm (MB)': f'{total_comm_mb:.1f}',\n",
    "        'Time (min)': f'{total_time_min:.1f}'\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä COMPREHENSIVE COMPARISON TABLE\")\n",
    "print(\"=\" * 80)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = results_dir / 'publication_comparison.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nüíæ Saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0971e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publication-quality plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Convergence curves\n",
    "for exp_name, results in experiments.items():\n",
    "    rounds = [rm['round'] for rm in results['round_metrics']]\n",
    "    accs = [rm['avg_accuracy'] for rm in results['round_metrics']]\n",
    "    axes[0, 0].plot(rounds, accs, 'o-', label=exp_name, linewidth=2.5, markersize=6)\n",
    "\n",
    "axes[0, 0].set_xlabel('Round', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Average Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_title('Convergence Comparison (30 Rounds)', fontsize=16, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11, loc='lower right')\n",
    "axes[0, 0].grid(True, alpha=0.3, linestyle='--')\n",
    "axes[0, 0].set_ylim([0.5, 1.0])\n",
    "\n",
    "# 2. Final accuracy with error bars\n",
    "exp_names = []\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "for exp_name, results in experiments.items():\n",
    "    accs = list(results['final_accuracies'].values())\n",
    "    exp_names.append(exp_name)\n",
    "    means.append(np.mean(accs))\n",
    "    stds.append(np.std(accs))\n",
    "\n",
    "bars = axes[0, 1].bar(range(len(exp_names)), means, \n",
    "                       color=['#2ecc71', '#3498db', '#e74c3c'][:len(exp_names)],\n",
    "                       edgecolor='black', linewidth=1.5)\n",
    "axes[0, 1].errorbar(range(len(exp_names)), means, yerr=stds, \n",
    "                    fmt='none', color='black', capsize=8, capthick=2)\n",
    "axes[0, 1].set_xticks(range(len(exp_names)))\n",
    "axes[0, 1].set_xticklabels(exp_names, rotation=15, ha='right')\n",
    "axes[0, 1].set_ylabel('Average Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_title('Final Accuracy (Mean ¬± Std)', fontsize=16, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "axes[0, 1].set_ylim([0.5, 1.0])\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, mean) in enumerate(zip(bars, means)):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + stds[i] + 0.02,\n",
    "                    f'{mean:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 3. Per-client accuracy (personalization)\n",
    "for exp_name, results in experiments.items():\n",
    "    client_ids = sorted(results['final_accuracies'].keys(), key=lambda x: int(x))\n",
    "    accs = [results['final_accuracies'][cid] for cid in client_ids]\n",
    "    axes[1, 0].plot(range(len(client_ids)), accs, 'o-', label=exp_name, \n",
    "                    linewidth=2.5, markersize=7)\n",
    "\n",
    "axes[1, 0].set_xlabel('Client ID', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_title('Per-Client Personalization', fontsize=16, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3, linestyle='--')\n",
    "axes[1, 0].set_ylim([0.5, 1.0])\n",
    "\n",
    "# 4. Communication cost\n",
    "comm_costs = []\n",
    "for exp_name, results in experiments.items():\n",
    "    total = 0\n",
    "    for rm in results['round_metrics']:\n",
    "        up = rm.get('comm_upload_bytes', {})\n",
    "        down = rm.get('comm_download_bytes', {})\n",
    "        if isinstance(up, dict):\n",
    "            total += sum(up.values()) + sum(down.values())\n",
    "        else:\n",
    "            total += up + down\n",
    "    comm_costs.append(total / (1024**2))\n",
    "\n",
    "axes[1, 1].bar(range(len(exp_names)), comm_costs,\n",
    "               color=['#2ecc71', '#3498db', '#e74c3c'][:len(exp_names)],\n",
    "               edgecolor='black', linewidth=1.5)\n",
    "axes[1, 1].set_xticks(range(len(exp_names)))\n",
    "axes[1, 1].set_xticklabels(exp_names, rotation=15, ha='right')\n",
    "axes[1, 1].set_ylabel('Total Communication (MB)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_title('Communication Overhead', fontsize=16, fontweight='bold')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = results_dir / 'publication_results.png'\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì High-resolution plot saved: {plot_path}\")\n",
    "print(\"  (300 DPI - suitable for IEEE publications)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb85956",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì¶ Download Results for Publication\n",
    "\n",
    "Package all results and figures for offline analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad163e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication package\n",
    "!zip -r atlas_publication_results.zip results/ figures/ checkpoints/ \\\n",
    "    -x \"*.pyc\" \"*__pycache__*\"\n",
    "\n",
    "print(\"‚úì Results packaged: atlas_publication_results.zip\")\n",
    "print(\"\\nContents:\")\n",
    "print(\"  - results/*.json (all experimental data)\")\n",
    "print(\"  - results/publication_comparison.csv\")\n",
    "print(\"  - results/publication_results.png (300 DPI)\")\n",
    "print(\"  - checkpoints/*.pkl (for resuming)\")\n",
    "\n",
    "# Download (in Colab)\n",
    "from google.colab import files\n",
    "files.download('atlas_publication_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb39d92",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Citation & IEEE Formatting\n",
    "\n",
    "**Suggested IEEE Paper Structure**:\n",
    "\n",
    "1. **Abstract**: Multi-task FL with heterogeneous devices + LoRA + Laplacian regularization\n",
    "2. **Introduction**: Challenges of FL for LLMs on edge devices\n",
    "3. **Related Work**: FedAvg, LoRA, Split Learning, MIRA, HSplitLoRA\n",
    "4. **Methodology**:\n",
    "   - Phase 1: Gradient-based clustering\n",
    "   - Phase 2: Heterogeneous rank allocation\n",
    "   - Phase 3: Split federated learning\n",
    "   - Phase 4: Graph-based personalization\n",
    "5. **Experiments**: \n",
    "   - Setup: 9 clients, 3 tasks, 30 rounds, 5000 samples\n",
    "   - Baselines: Local Only, FedAvg per Cluster\n",
    "   - Results: Convergence, accuracy, communication, ablations\n",
    "6. **Results & Discussion**: Show plots from above\n",
    "7. **Conclusion**: ATLAS enables personalized LLM fine-tuning on heterogeneous edge devices\n",
    "\n",
    "**Key Metrics for IEEE Paper**:\n",
    "- Convergence rate (rounds to 90% of final accuracy)\n",
    "- Final accuracy (mean ¬± std across clients)\n",
    "- Communication cost (MB per round, total MB)\n",
    "- Personalization quality (variance, per-task accuracy)\n",
    "- Ablation study results (with/without each phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbaf0f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Session Management Cheat Sheet\n",
    "\n",
    "### Start new experiment:\n",
    "```bash\n",
    "python experiments/atlas_integrated.py --mode full --rounds 30 --max-rounds 15\n",
    "```\n",
    "\n",
    "### Resume from checkpoint:\n",
    "```bash\n",
    "python experiments/atlas_integrated.py --mode full --rounds 30 \\\\\n",
    "    --resume checkpoints/atlas_round_15.pkl\n",
    "```\n",
    "\n",
    "### Change model:\n",
    "```bash\n",
    "python experiments/atlas_integrated.py --model bert-base-uncased\n",
    "```\n",
    "\n",
    "### Change tasks:\n",
    "```bash\n",
    "python experiments/atlas_integrated.py --tasks sst2 mrpc qnli mnli\n",
    "```\n",
    "\n",
    "### Override parameters:\n",
    "```bash\n",
    "python experiments/atlas_integrated.py --samples 3000 --local-epochs 2\n",
    "```\n",
    "\n",
    "### Check available checkpoints:\n",
    "```bash\n",
    "ls -lh checkpoints/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
