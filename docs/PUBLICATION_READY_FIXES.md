# üéØ Publication-Ready ATLAS: Fixes for MIRA Alignment

## Overview

This document summarizes the three critical fixes implemented to move ATLAS from toy experiments (4 clients, uniform ranks, fragmented clustering) to publication-level results aligned with the MIRA paper.

---

## ‚úÖ Fix 1: Singleton Penalty in Clustering

### Problem

Previous runs produced k=5 clusters with 2 singletons (clients 4 and 6), fragmenting MRPC and CoLA tasks. Singletons don't benefit from:

- Intra-cluster averaging
- Dense Laplacian neighborhoods
- MIRA's assumption of connected task graphs

### Solution

Added **singleton penalty** to clustering combined score:

```python
# src/phase1_clustering.py
cluster_sizes = np.bincount(labels)
n_singletons = np.sum(cluster_sizes == 1)
singleton_penalty = 0.15 * n_singletons  # Penalize fragmentation

combined = 0.5 * sil_norm + 0.3 * db_norm + 0.2 * ch_norm - singleton_penalty
```

### Expected Impact

- Prefer k=3 (one cluster per task) unless strong evidence for splitting
- Each cluster has ‚â•2 clients for meaningful within-cluster aggregation
- Better alignment with MIRA's multi-task graph structure

### Verification

```bash
# Look for this in clustering output:
# k=3: Combined=0.65 (Sil=0.12, DB=0.89, Temporal=1.0, Singletons=0)
# k=5: Combined=0.52 (Sil=0.05, DB=1.01, Temporal=1.0, Singletons=2)
# Selected k=3 (no singletons!)
```

---

## ‚úÖ Fix 2: Per-Layer Rank Variation via Tighter Memory Budget

### Problem

Previous runs assigned **uniform ranks** across layers (e.g., [8,8,8,8,8,8] for 2GB, [64,64,64,64,64,64] for 16GB) despite:

- Computing per-layer importance scores correctly (0.009 to 0.266)
- Having greedy allocator logic that prioritizes high-importance layers

**Root cause**: Memory budget too permissive ‚Üí allocator upgrades all layers to max rank simultaneously.

### Solution

Reduced **alpha_opt** from 0.15 to 0.08 in memory budget:

```python
# experiments/atlas_integrated.py - ATLASConfig
alpha_opt: float = 0.08  # Reduced from 0.15 to force per-layer variation

# Memory constraint: Œ£(2¬∑d¬∑r_‚Ñì¬∑b) ‚â§ C_mem¬∑(1 - alpha_base - alpha_act - alpha_opt)
```

This creates a **tighter constraint**, forcing the greedy allocator to make trade-offs:

- Assign higher ranks to important layers (layer_3, layer_2)
- Assign lower ranks to less important layers (layer_5, layer_0)

### Expected Impact

Heterogeneous ranks **within** device classes, e.g.:

```
2GB CPU: [4, 8, 16, 16, 8, 4]   # Focus on middle layers
8GB Laptop: [16, 32, 64, 64, 32, 16]
16GB GPU: [32, 64, 128, 128, 64, 32]
```

This matches **HSplitLoRA** and **MIRA's importance-aware allocation**.

### Verification

```bash
# Look for heterogeneous ranks in Phase 2 output:
# Client 0 (cpu_2gb): ranks=[4, 8, 16, 16, 8, 4]
# Client 3 (laptop_8gb): ranks=[16, 32, 64, 64, 32, 16]
# Client 6 (gpu_16gb): ranks=[32, 64, 128, 128, 64, 32]
```

---

## ‚úÖ Fix 3: Improved Singleton Connectivity Logging

### Problem

Singletons were connected to k=3 nearest neighbors, but we couldn't verify:

- Which clients they connected to
- Whether all singletons got full connectivity (expected 16 edges, got 10)

### Solution

Enhanced logging in `src/phase4_laplacian.py`:

```python
# Log singleton connectivity
neighbor_ids = [cid for cid, _ in neighbor_weights]
logger.info(f"Singleton client {singleton_id} connected to {neighbor_ids} "
            f"with weights {[f'{w:.3f}' for _, w in neighbor_weights]}")
```

### Expected Impact

Clear verification of:

- Which clients each singleton connects to
- RBF weights for singleton edges
- Whether we achieve full connectivity

### Verification

```bash
# Look for INFO logs:
# Singleton client 4 connected to [3, 5, 6] with weights ['0.523', '0.481', '0.398']
# Singleton client 6 connected to [5, 7, 8] with weights ['0.512', '0.487', '0.405']
```

---

## üß™ Recommended Next Experiments

### 1. **Quick Run with Fixes** (5-10 min)

Verify all fixes work together:

```bash
python experiments/atlas_integrated.py \
  --quick \
  --num-rounds 3
```

**Look for**:

- ‚úÖ k=3 selected (no singletons)
- ‚úÖ Heterogeneous ranks: [4,8,16,16,8,4] vs [32,64,128,128,64,32]
- ‚úÖ Clear singleton connectivity logs (if any singletons remain)

---

### 2. **Full 20-Round Run** (30-40 min)

Publication-level experiment:

```bash
python experiments/atlas_integrated.py \
  --num-rounds 20 \
  --clients-per-task 3
```

**Metrics to track**:

- Per-task accuracy curves (SST-2, MRPC, CoLA)
- Per-client variance within tasks
- Convergence speed vs FedAvg baseline

---

### 3. **Lambda Sweep** (2-3 hours)

Test Laplacian regularization strength:

```bash
for eta in 0.0 0.01 0.1 0.5 1.0; do
  python experiments/atlas_integrated.py \
    --num-rounds 20 \
    --eta $eta \
    --tag "lambda_$eta"
done
```

**Compare**:

- Œ∑=0.0: No Laplacian (baseline)
- Œ∑=0.01-0.1: Light regularization
- Œ∑=0.5-1.0: Strong smoothing

**Expected**: Œ∑‚âà0.1 optimal (MIRA uses Œª‚âà0.05-0.2).

---

### 4. **Ablation Study**

Compare graph structures:

```bash
# A. Local-only (no federation)
python experiments/atlas_integrated.py --ablation local_only

# B. FedAvg within clusters
python experiments/atlas_integrated.py --ablation fedavg_cluster

# C. Full ATLAS (Laplacian)
python experiments/atlas_integrated.py --ablation atlas
```

**Generate MIRA-style table**:
| Method | SST-2 | MRPC | CoLA | Avg |
|--------|-------|------|------|-----|
| Local | 0.82 | 0.70 | 0.68 | 0.73 |
| FedAvg | 0.84 | 0.74 | 0.72 | 0.77 |
| ATLAS | 0.85 | 0.78 | 0.75 | 0.79 |

---

## üìä Expected Results

### Clustering

```
k=3 selected (score=0.65, singletons=0):
  Cluster 0: [0,1,2] (SST-2, 3 clients)
  Cluster 1: [3,4,5] (MRPC, 3 clients)
  Cluster 2: [6,7,8] (CoLA, 3 clients)
```

### Heterogeneous Ranks

```
Device Type | Ranks (6 layers)
------------|------------------
2GB CPU     | [4, 8, 16, 16, 8, 4]
4GB Tablet  | [8, 16, 32, 32, 16, 8]
8GB Laptop  | [16, 32, 64, 64, 32, 16]
16GB GPU    | [32, 64, 128, 128, 64, 32]
```

### Task Graph

```
MIRA adjacency (mira_rbf):
  9 edges within clusters (3+3+3)
  Block-diagonal structure
  RBF weights: a_{k,‚Ñì} = exp(-Œ±||f_k - f_‚Ñì||¬≤)
```

---

## üéì Alignment with MIRA Paper

| MIRA Component               | ATLAS Implementation                                        | Status      |
| ---------------------------- | ----------------------------------------------------------- | ----------- | --- | --- |
| **Task-aware clustering**    | Gradient fingerprints + PCA + KMeans with singleton penalty | ‚úÖ          |
| **Importance-aware LoRA**    | Per-layer gradient norms ‚Üí greedy rank allocation           | ‚úÖ          |
| **RBF adjacency**            | a\_{k,‚Ñì} = exp(-Œ±\\                                         | f*k - f*‚Ñì\\ | ¬≤)  | ‚úÖ  |
| **Block-diagonal graph**     | No cross-cluster edges                                      | ‚úÖ          |
| **Laplacian regularization** | Œ∏*k^{t+1} += Œ∑¬∑Œ£ a*{k,‚Ñì}(Œ∏_‚Ñì - Œ∏_k)                         | ‚úÖ          |
| **Lambda tuning**            | CLI flag `--eta` for sweep                                  | ‚úÖ          |
| **Ablation modes**           | local_only, fedavg_cluster, atlas                           | ‚úÖ          |

---

## üöÄ Quick Start

```bash
# 1. Test fixes (3 rounds, ~5 min)
python experiments/atlas_integrated.py --quick --num-rounds 3

# 2. Full run (20 rounds, ~40 min)
python experiments/atlas_integrated.py --num-rounds 20

# 3. Lambda sweep (5 values √ó 20 rounds, ~3 hours)
for eta in 0.0 0.01 0.1 0.5 1.0; do
  python experiments/atlas_integrated.py --num-rounds 20 --eta $eta --tag "lambda_$eta"
done

# 4. Generate comparison plots
python experiments/visualize.py \
  --results results/*lambda*.json \
  --output figures/lambda_sweep.png
```

---

## üìù Notes

- **Memory budget math**: C_lora = C_mem √ó (1 - Œ±_base - Œ±_act - Œ±_opt) = 16GB √ó (1 - 0.5 - 0.25 - 0.08) = 2.72GB for LoRA
- **Greedy allocator**: Sorts layers by importance, tries ranks [128, 64, 32, 16, 8, 4] descending, picks highest under budget
- **Singleton connectivity**: Uses k=3 nearest neighbors via fingerprint distance (no cluster restriction)

---

## ‚úÖ Commit

All fixes pushed to main:

```
commit 87ad032
Fix 3 issues for publication-level ATLAS:
1) Singleton penalty in clustering
2) Tighter memory budget for per-layer variation
3) Improved connectivity logging
```
