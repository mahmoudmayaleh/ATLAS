[MODE] Quick test (20-30 min on T4 GPU)
config.json: 100% 483/483 [00:00<00:00, 2.16MB/s]
tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 188kB/s]
vocab.txt: 100% 232k/232k [00:00<00:00, 1.94MB/s]
tokenizer.json: 100% 466k/466k [00:00<00:00, 31.2MB/s]

[SETUP] Creating multi-task federated learning setup...
  Loading task: sst2
README.md: 5.27kB [00:00, 12.7MB/s]
data/train-00000-of-00001.parquet: 100% 3.11M/3.11M [00:01<00:00, 2.44MB/s]
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
data/validation-00000-of-00001.parquet: 100% 72.8k/72.8k [00:00<00:00, 140kB/s]
data/test-00000-of-00001.parquet: 100% 148k/148k [00:00<00:00, 242kB/s]  
Generating train split: 100% 67349/67349 [00:00<00:00, 1057237.31 examples/s]
Generating validation split: 100% 872/872 [00:00<00:00, 383781.02 examples/s]
Generating test split: 100% 1821/1821 [00:00<00:00, 623954.54 examples/s]
Map: 100% 67349/67349 [00:08<00:00, 7489.73 examples/s]
Map: 100% 872/872 [00:00<00:00, 7461.76 examples/s]
    Client 0: sst2, cpu_2gb, 500 samples
    Client 1: sst2, cpu_2gb, 500 samples
  Loading task: mrpc
README.md: 35.3kB [00:00, 70.1MB/s]
mrpc/train-00000-of-00001.parquet: 100% 649k/649k [00:00<00:00, 904kB/s]  
mrpc/validation-00000-of-00001.parquet: 100% 75.7k/75.7k [00:00<00:00, 136kB/s]
mrpc/test-00000-of-00001.parquet: 100% 308k/308k [00:00<00:00, 497kB/s]
Generating train split: 100% 3668/3668 [00:00<00:00, 383218.93 examples/s]
Generating validation split: 100% 408/408 [00:00<00:00, 144411.48 examples/s]
Generating test split: 100% 1725/1725 [00:00<00:00, 322236.42 examples/s]
Map: 100% 3668/3668 [00:00<00:00, 4611.69 examples/s]
Map: 100% 408/408 [00:00<00:00, 4475.04 examples/s]
    Client 2: mrpc, tablet_4gb, 500 samples
    Client 3: mrpc, tablet_4gb, 500 samples
  ✓ Created 4 clients across 2 tasks

[ATLAS] Initialized with:
  Model: distilbert-base-uncased
  Tasks: ['sst2', 'mrpc']
  Total clients: 4
  Device types: {'tablet_4gb', 'cpu_2gb'}
  Device: cuda

======================================================================
ATLAS INTEGRATED EXPERIMENT
======================================================================


======================================================================
PHASE 1: TASK CLUSTERING
======================================================================

[Phase 1] Extracting gradient fingerprints...
  Client 0 (sst2)... ✓ raw grad dict: 36 tensors, total_params=14767874
  Client 1 (sst2)... ✓ raw grad dict: 36 tensors, total_params=14767874
  Client 2 (mrpc)... ✓ raw grad dict: 36 tensors, total_params=14767874
  Client 3 (mrpc)... ✓ raw grad dict: 36 tensors, total_params=14767874

[Phase 1] Fitting fingerprint PCA on 4 samples...
PCA fitted: 4 samples, 14767874 features
Using 4 components (target was 64)
Explained variance ratio: 1.0000
Top 3 components explain: 1.0000

[Phase 1] Clustering 4 clients...
k=2: Combined=0.3919 (Sil=0.044, DB=1.297, Temporal=1.000)
k=3: Combined=0.4503 (Sil=0.018, DB=0.535, Temporal=1.000)

✓ Best clustering: k=3
  Combined Score: 0.4503
  Silhouette: 0.0183
  Davies-Bouldin: 0.5348
  Calinski-Harabasz: 1.14
  Temporal Consistency: 1.0000
  ✓ Found 3 task groups

[Phase 1] Cluster-Task Alignment Analysis:
    Cluster 0: 1 clients
      Tasks: {'mrpc': 1} (dominant: mrpc, purity: 1.00)
      Client IDs: [3]
    Cluster 1: 2 clients
      Tasks: {'sst2': 2} (dominant: sst2, purity: 1.00)
      Client IDs: [0, 1]
    Cluster 2: 1 clients
      Tasks: {'mrpc': 1} (dominant: mrpc, purity: 1.00)
      Client IDs: [2]

  ✓ Average cluster purity: 1.000

======================================================================
PHASE 2: HETEROGENEOUS RANK ALLOCATION
======================================================================

[Phase 2] Profiling devices and allocating ranks...

[Phase 2] Computing cluster-level statistics...
  Cluster 0: variance=0.0000, norm=1.0000, complexity=0.0000
  Cluster 1: variance=0.0095, norm=1.0000, complexity=0.0095
  Cluster 2: variance=0.0000, norm=1.0000, complexity=0.0000

[Phase 2] Allocating heterogeneous ranks per client...
  Client 0 (cpu_2gb, cluster 1): ranks=[8, 8, 8, 8, 8, 8], memory=0.3MB, valid=True
  Client 1 (cpu_2gb, cluster 1): ranks=[8, 8, 8, 8, 8, 8], memory=0.3MB, valid=True
  Client 2 (tablet_4gb, cluster 2): ranks=[16, 16, 16, 16, 16, 16], memory=0.6MB, valid=True
  Client 3 (tablet_4gb, cluster 0): ranks=[16, 16, 16, 16, 16, 16], memory=0.6MB, valid=True

✓ Phase 2 complete: Allocated heterogeneous ranks for 4 clients

======================================================================
PHASE 3 & 4: SPLIT FL + LAPLACIAN REGULARIZATION
======================================================================

[Phase 3&4] Initializing split FL clients and server...

[Phase 4] Building task graph with mira_rbf adjacency...
  ✓ Computed 2 adjacency weights using mira_rbf
  Sample weights: [((0, 1), np.float64(1.0)), ((1, 0), np.float64(1.0))]
  ✓ Created 4 personalized client models

======================================================================
ROUND 1/20
======================================================================

[Round 1] Local training...
    Client 0 (sst2): 64 batches, loss=0.6843
    Client 1 (sst2): 64 batches, loss=0.6719
    Client 2 (mrpc): 64 batches, loss=0.6354
    Client 3 (mrpc): 64 batches, loss=0.6552

[Round 1] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 1] Applying Laplacian regularization...

[Round 1] Evaluation...
  Client 0 (sst2): acc=0.5138, f1=0.3497, loss=0.6769
  Client 1 (sst2): acc=0.5092, f1=0.3374, loss=0.6845
  Client 2 (mrpc): acc=0.6838, f1=0.4061, loss=0.6140
  Client 3 (mrpc): acc=0.6838, f1=0.4061, loss=0.6190

[Round 1] Avg accuracy: 0.5976, Time: 37.3s

======================================================================
ROUND 2/20
======================================================================

[Round 2] Local training...
    Client 0 (sst2): 64 batches, loss=0.6694
    Client 1 (sst2): 64 batches, loss=0.6485
    Client 2 (mrpc): 64 batches, loss=0.5983
    Client 3 (mrpc): 64 batches, loss=0.6249

[Round 2] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 2] Applying Laplacian regularization...

[Round 2] Evaluation...
  Client 0 (sst2): acc=0.6571, f1=0.6222, loss=0.6527
  Client 1 (sst2): acc=0.5161, f1=0.3528, loss=0.6567
  Client 2 (mrpc): acc=0.6838, f1=0.4061, loss=0.6095
  Client 3 (mrpc): acc=0.6838, f1=0.4061, loss=0.6151

[Round 2] Avg accuracy: 0.6352, Time: 39.3s

======================================================================
ROUND 3/20
======================================================================

[Round 3] Local training...
    Client 0 (sst2): 64 batches, loss=0.6411
    Client 1 (sst2): 64 batches, loss=0.6047
    Client 2 (mrpc): 64 batches, loss=0.5859
    Client 3 (mrpc): 64 batches, loss=0.6253

[Round 3] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 3] Applying Laplacian regularization...

[Round 3] Evaluation...
  Client 0 (sst2): acc=0.7649, f1=0.7601, loss=0.6148
  Client 1 (sst2): acc=0.6365, f1=0.5819, loss=0.6050
  Client 2 (mrpc): acc=0.6838, f1=0.4061, loss=0.6033
  Client 3 (mrpc): acc=0.6838, f1=0.4061, loss=0.6123

[Round 3] Avg accuracy: 0.6923, Time: 39.3s

======================================================================
ROUND 4/20
======================================================================

[Round 4] Local training...
    Client 0 (sst2): 64 batches, loss=0.5903
    Client 1 (sst2): 64 batches, loss=0.5505
    Client 2 (mrpc): 64 batches, loss=0.5752
    Client 3 (mrpc): 64 batches, loss=0.6145

[Round 4] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 4] Applying Laplacian regularization...

[Round 4] Evaluation...
  Client 0 (sst2): acc=0.8062, f1=0.8060, loss=0.5535
  Client 1 (sst2): acc=0.7661, f1=0.7579, loss=0.5393
  Client 2 (mrpc): acc=0.6961, f1=0.4464, loss=0.6000
  Client 3 (mrpc): acc=0.6838, f1=0.4061, loss=0.6087

[Round 4] Avg accuracy: 0.7380, Time: 39.1s

======================================================================
ROUND 5/20
======================================================================

[Round 5] Local training...
    Client 0 (sst2): 64 batches, loss=0.5148
    Client 1 (sst2): 64 batches, loss=0.4644
    Client 2 (mrpc): 64 batches, loss=0.5592
    Client 3 (mrpc): 64 batches, loss=0.6062

[Round 5] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 5] Applying Laplacian regularization...

[Round 5] Evaluation...
  Client 0 (sst2): acc=0.8165, f1=0.8164, loss=0.4790
  Client 1 (sst2): acc=0.8280, f1=0.8278, loss=0.4544
  Client 2 (mrpc): acc=0.7059, f1=0.4884, loss=0.5967
  Client 3 (mrpc): acc=0.6838, f1=0.4061, loss=0.6052

[Round 5] Avg accuracy: 0.7586, Time: 39.3s
[CHECKPOINT] Saved to checkpoints/atlas_round_5.pkl

======================================================================
ROUND 6/20
======================================================================

[Round 6] Local training...
    Client 0 (sst2): 64 batches, loss=0.4363
    Client 1 (sst2): 64 batches, loss=0.3898
    Client 2 (mrpc): 64 batches, loss=0.5505
    Client 3 (mrpc): 64 batches, loss=0.5998

[Round 6] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 6] Applying Laplacian regularization...

[Round 6] Evaluation...
  Client 0 (sst2): acc=0.8200, f1=0.8200, loss=0.4239
  Client 1 (sst2): acc=0.8280, f1=0.8277, loss=0.4080
  Client 2 (mrpc): acc=0.7157, f1=0.5213, loss=0.5937
  Client 3 (mrpc): acc=0.6838, f1=0.4061, loss=0.6013

[Round 6] Avg accuracy: 0.7619, Time: 39.9s

======================================================================
ROUND 7/20
======================================================================

[Round 7] Local training...
    Client 0 (sst2): 64 batches, loss=0.3934
    Client 1 (sst2): 64 batches, loss=0.3307
    Client 2 (mrpc): 64 batches, loss=0.5358
    Client 3 (mrpc): 64 batches, loss=0.5919

[Round 7] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 7] Applying Laplacian regularization...

[Round 7] Evaluation...
  Client 0 (sst2): acc=0.8211, f1=0.8211, loss=0.4001
  Client 1 (sst2): acc=0.8291, f1=0.8289, loss=0.3859
  Client 2 (mrpc): acc=0.7132, f1=0.5246, loss=0.5932
  Client 3 (mrpc): acc=0.6838, f1=0.4061, loss=0.5976

[Round 7] Avg accuracy: 0.7618, Time: 39.3s

======================================================================
ROUND 8/20
======================================================================

[Round 8] Local training...
    Client 0 (sst2): 64 batches, loss=0.3610
    Client 1 (sst2): 64 batches, loss=0.3113
    Client 2 (mrpc): 64 batches, loss=0.5301
    Client 3 (mrpc): 64 batches, loss=0.5820

[Round 8] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 8] Applying Laplacian regularization...

[Round 8] Evaluation...
  Client 0 (sst2): acc=0.8188, f1=0.8188, loss=0.3906
  Client 1 (sst2): acc=0.8268, f1=0.8268, loss=0.3790
  Client 2 (mrpc): acc=0.7083, f1=0.5352, loss=0.5912
  Client 3 (mrpc): acc=0.6863, f1=0.4144, loss=0.5936

[Round 8] Avg accuracy: 0.7601, Time: 39.3s

======================================================================
ROUND 9/20
======================================================================

[Round 9] Local training...
    Client 0 (sst2): 64 batches, loss=0.3434
    Client 1 (sst2): 64 batches, loss=0.3140
    Client 2 (mrpc): 64 batches, loss=0.5270
    Client 3 (mrpc): 64 batches, loss=0.5833

[Round 9] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 9] Applying Laplacian regularization...

[Round 9] Evaluation...
  Client 0 (sst2): acc=0.8245, f1=0.8244, loss=0.3880
  Client 1 (sst2): acc=0.8268, f1=0.8268, loss=0.3798
  Client 2 (mrpc): acc=0.7034, f1=0.5404, loss=0.5895
  Client 3 (mrpc): acc=0.6912, f1=0.4306, loss=0.5896

[Round 9] Avg accuracy: 0.7615, Time: 39.3s

======================================================================
ROUND 10/20
======================================================================

[Round 10] Local training...
    Client 0 (sst2): 64 batches, loss=0.3247
    Client 1 (sst2): 64 batches, loss=0.2887
    Client 2 (mrpc): 64 batches, loss=0.5054
    Client 3 (mrpc): 64 batches, loss=0.5661

[Round 10] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 10] Applying Laplacian regularization...

[Round 10] Evaluation...
  Client 0 (sst2): acc=0.8211, f1=0.8211, loss=0.3847
  Client 1 (sst2): acc=0.8337, f1=0.8336, loss=0.3801
  Client 2 (mrpc): acc=0.7059, f1=0.5542, loss=0.5881
  Client 3 (mrpc): acc=0.6887, f1=0.4296, loss=0.5852

[Round 10] Avg accuracy: 0.7624, Time: 39.3s
[CHECKPOINT] Saved to checkpoints/atlas_round_10.pkl

======================================================================
ROUND 11/20
======================================================================

[Round 11] Local training...
    Client 0 (sst2): 64 batches, loss=0.3252
    Client 1 (sst2): 64 batches, loss=0.2851
    Client 2 (mrpc): 64 batches, loss=0.4954
    Client 3 (mrpc): 64 batches, loss=0.5526

[Round 11] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 11] Applying Laplacian regularization...

[Round 11] Evaluation...
  Client 0 (sst2): acc=0.8291, f1=0.8291, loss=0.3821
  Client 1 (sst2): acc=0.8257, f1=0.8257, loss=0.3780
  Client 2 (mrpc): acc=0.7010, f1=0.5544, loss=0.5845
  Client 3 (mrpc): acc=0.6961, f1=0.4772, loss=0.5802

[Round 11] Avg accuracy: 0.7630, Time: 39.8s

======================================================================
ROUND 12/20
======================================================================

[Round 12] Local training...
    Client 0 (sst2): 64 batches, loss=0.3043
    Client 1 (sst2): 64 batches, loss=0.2830
    Client 2 (mrpc): 64 batches, loss=0.4888
    Client 3 (mrpc): 64 batches, loss=0.5420

[Round 12] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 12] Applying Laplacian regularization...

[Round 12] Evaluation...
  Client 0 (sst2): acc=0.8268, f1=0.8267, loss=0.3820
  Client 1 (sst2): acc=0.8268, f1=0.8268, loss=0.3766
  Client 2 (mrpc): acc=0.7059, f1=0.5542, loss=0.5872
  Client 3 (mrpc): acc=0.7034, f1=0.4980, loss=0.5765

[Round 12] Avg accuracy: 0.7657, Time: 39.2s

======================================================================
ROUND 13/20
======================================================================

[Round 13] Local training...
    Client 0 (sst2): 64 batches, loss=0.2892
    Client 1 (sst2): 64 batches, loss=0.2671
    Client 2 (mrpc): 64 batches, loss=0.4807
    Client 3 (mrpc): 64 batches, loss=0.5225

[Round 13] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 13] Applying Laplacian regularization...

[Round 13] Evaluation...
  Client 0 (sst2): acc=0.8188, f1=0.8188, loss=0.3831
  Client 1 (sst2): acc=0.8291, f1=0.8291, loss=0.3771
  Client 2 (mrpc): acc=0.7059, f1=0.5689, loss=0.5821
  Client 3 (mrpc): acc=0.7010, f1=0.5068, loss=0.5723

[Round 13] Avg accuracy: 0.7637, Time: 39.3s

======================================================================
ROUND 14/20
======================================================================

[Round 14] Local training...
    Client 0 (sst2): 64 batches, loss=0.2813
    Client 1 (sst2): 64 batches, loss=0.2508
    Client 2 (mrpc): 64 batches, loss=0.4674
    Client 3 (mrpc): 64 batches, loss=0.5111

[Round 14] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 14] Applying Laplacian regularization...

[Round 14] Evaluation...
  Client 0 (sst2): acc=0.8257, f1=0.8257, loss=0.3809
  Client 1 (sst2): acc=0.8337, f1=0.8336, loss=0.3854
  Client 2 (mrpc): acc=0.7034, f1=0.5635, loss=0.5845
  Client 3 (mrpc): acc=0.7010, f1=0.5118, loss=0.5694

[Round 14] Avg accuracy: 0.7660, Time: 39.3s

======================================================================
ROUND 15/20
======================================================================

[Round 15] Local training...
    Client 0 (sst2): 64 batches, loss=0.2657
    Client 1 (sst2): 64 batches, loss=0.2546
    Client 2 (mrpc): 64 batches, loss=0.4560
    Client 3 (mrpc): 64 batches, loss=0.4913

[Round 15] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 15] Applying Laplacian regularization...

[Round 15] Evaluation...
  Client 0 (sst2): acc=0.8268, f1=0.8268, loss=0.3793
  Client 1 (sst2): acc=0.8314, f1=0.8313, loss=0.3841
  Client 2 (mrpc): acc=0.7132, f1=0.5847, loss=0.5836
  Client 3 (mrpc): acc=0.7010, f1=0.5302, loss=0.5678

[Round 15] Avg accuracy: 0.7681, Time: 39.2s
[CHECKPOINT] Saved to checkpoints/atlas_round_15.pkl

======================================================================
ROUND 16/20
======================================================================

[Round 16] Local training...
    Client 0 (sst2): 64 batches, loss=0.2728
    Client 1 (sst2): 64 batches, loss=0.2466
    Client 2 (mrpc): 64 batches, loss=0.4369
    Client 3 (mrpc): 64 batches, loss=0.4803

[Round 16] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 16] Applying Laplacian regularization...

[Round 16] Evaluation...
  Client 0 (sst2): acc=0.8234, f1=0.8234, loss=0.3786
  Client 1 (sst2): acc=0.8314, f1=0.8313, loss=0.3835
  Client 2 (mrpc): acc=0.7157, f1=0.5866, loss=0.5853
  Client 3 (mrpc): acc=0.7059, f1=0.5943, loss=0.5634

[Round 16] Avg accuracy: 0.7691, Time: 39.8s

======================================================================
ROUND 17/20
======================================================================

[Round 17] Local training...
    Client 0 (sst2): 64 batches, loss=0.2520
    Client 1 (sst2): 64 batches, loss=0.2295
    Client 2 (mrpc): 64 batches, loss=0.4235
    Client 3 (mrpc): 64 batches, loss=0.4644

[Round 17] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 17] Applying Laplacian regularization...

[Round 17] Evaluation...
  Client 0 (sst2): acc=0.8234, f1=0.8234, loss=0.3803
  Client 1 (sst2): acc=0.8314, f1=0.8313, loss=0.3884
  Client 2 (mrpc): acc=0.7108, f1=0.5952, loss=0.5817
  Client 3 (mrpc): acc=0.6985, f1=0.5967, loss=0.5616

[Round 17] Avg accuracy: 0.7660, Time: 39.1s

======================================================================
ROUND 18/20
======================================================================

[Round 18] Local training...
    Client 0 (sst2): 64 batches, loss=0.2443
    Client 1 (sst2): 64 batches, loss=0.2302
    Client 2 (mrpc): 64 batches, loss=0.4134
    Client 3 (mrpc): 64 batches, loss=0.4574

[Round 18] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 18] Applying Laplacian regularization...

[Round 18] Evaluation...
  Client 0 (sst2): acc=0.8234, f1=0.8234, loss=0.3775
  Client 1 (sst2): acc=0.8314, f1=0.8313, loss=0.3873
  Client 2 (mrpc): acc=0.7181, f1=0.5981, loss=0.5879
  Client 3 (mrpc): acc=0.6912, f1=0.5855, loss=0.5631

[Round 18] Avg accuracy: 0.7660, Time: 39.3s

======================================================================
ROUND 19/20
======================================================================

[Round 19] Local training...
    Client 0 (sst2): 64 batches, loss=0.2279
    Client 1 (sst2): 64 batches, loss=0.2265
    Client 2 (mrpc): 64 batches, loss=0.4062
    Client 3 (mrpc): 64 batches, loss=0.4540

[Round 19] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 19] Applying Laplacian regularization...

[Round 19] Evaluation...
  Client 0 (sst2): acc=0.8280, f1=0.8279, loss=0.3830
  Client 1 (sst2): acc=0.8326, f1=0.8324, loss=0.3902
  Client 2 (mrpc): acc=0.7132, f1=0.6085, loss=0.5787
  Client 3 (mrpc): acc=0.7157, f1=0.6050, loss=0.5672

[Round 19] Avg accuracy: 0.7724, Time: 39.3s

======================================================================
ROUND 20/20
======================================================================

[Round 20] Local training...
    Client 0 (sst2): 64 batches, loss=0.2238
    Client 1 (sst2): 64 batches, loss=0.2082
    Client 2 (mrpc): 64 batches, loss=0.3880
    Client 3 (mrpc): 64 batches, loss=0.4298

[Round 20] Task-aware aggregation...
  Group 0: aggregating 1 clients
  Group 1: aggregating 2 clients
  Group 2: aggregating 1 clients

[Round 20] Applying Laplacian regularization...

[Round 20] Evaluation...
  Client 0 (sst2): acc=0.8280, f1=0.8280, loss=0.3833
  Client 1 (sst2): acc=0.8360, f1=0.8360, loss=0.3889
  Client 2 (mrpc): acc=0.7181, f1=0.6011, loss=0.5863
  Client 3 (mrpc): acc=0.6961, f1=0.6025, loss=0.5640

[Round 20] Avg accuracy: 0.7696, Time: 39.2s
[CHECKPOINT] Saved to checkpoints/atlas_round_20.pkl

======================================================================
[DONE] ATLAS pipeline complete!
  Total time: 16.7 minutes
  Final per-client accuracy: {0: 0.8279816513761468, 1: 0.8360091743119266, 2: 0.7181372549019608, 3: 0.696078431372549}
======================================================================